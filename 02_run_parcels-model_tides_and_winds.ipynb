{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037c1857",
   "metadata": {},
   "source": [
    "# Example for running parcels 3.0\n",
    "\n",
    "\n",
    "The cell below only checks the version for the main Software used in this notebook. However, the environment is locked in the conda-lock.yml file for full reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec855b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy\n",
    "import parcels\n",
    "import xarray\n",
    "\n",
    "print(f\"{parcels.__version__=}\")\n",
    "print(f\"{xarray.__version__=}\")\n",
    "print(f\"{cartopy.__version__=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f1f9e",
   "metadata": {},
   "source": [
    "Download and cache the model data from the GitHub repository. We are using here the model with both winds and tides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcdf5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch\n",
    "import xarray as xr\n",
    "\n",
    "url = \"https://github.com/LaPoGeoMar/Proj_Modelagem_Pellet/releases/download\"\n",
    "version = \"v0.1.0\"\n",
    "\n",
    "fname = pooch.retrieve(\n",
    "    url=f\"{url}/{version}/model_tides_and_winds.nc\",\n",
    "    known_hash=\"sha256:1b01945c529e9f0489a659fc8360344ff58925544a2f7e543148d4f31c6dd0e8\",\n",
    ")\n",
    "\n",
    "ds = xr.open_dataset(fname)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8e249",
   "metadata": {},
   "source": [
    "We need to trim the borders [1] b/c the duplicated position at the bordes crashes the integration. We also transpose the matrix b/c `parcels` expect the arrays to be in time, lat, lon order.\n",
    "\n",
    "[1] https://github.com/OceanParcels/parcels/issues/1358\n",
    "[2] https://github.com/OceanParcels/parcels/issues/1235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e353de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start: 2021-01-01T00:00:00.000000000\n",
    "# End: 2022-01-01T00:00:00.000000000\n",
    "\n",
    "ds = ds.isel(\n",
    "    m=slice(1, -1),\n",
    "    n=slice(1, -1),\n",
    ")\n",
    "\n",
    "ds = ds.transpose(\"time\", \"n\", \"m\")\n",
    "ds = ds.sel(time=slice(\"2021-02\", \"2021-03\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d02e6",
   "metadata": {},
   "source": [
    "Create the `FieldSet` from the xarray dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4ede09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parcels import FieldSet\n",
    "\n",
    "variables = {\n",
    "    \"U\": \"velocity_x\",\n",
    "    \"V\": \"velocity_y\",\n",
    "}\n",
    "\n",
    "dimensions = {\n",
    "    \"U\": {\n",
    "        \"time\": \"time\",\n",
    "        \"lat\": \"n\",  # \"latitude\",\n",
    "        \"lon\": \"m\",  # \"longitude\",\n",
    "    },\n",
    "    \"V\": {\n",
    "        \"time\": \"time\",\n",
    "        \"lat\": \"n\",  # \"latitude\",\n",
    "        \"lon\": \"m\",  # \"longitude\",\n",
    "    },\n",
    "}\n",
    "\n",
    "fieldset = FieldSet.from_xarray_dataset(ds, variables, dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048f9c3",
   "metadata": {},
   "source": [
    "Find the nearest grid point to the position `x, y` to release the particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ab36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "offset = 0.1  # make it away from the coast\n",
    "x, y = -48.66 + offset, -26.89  # Itajaí\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "\n",
    "xi = find_nearest(ds[\"m\"], x)\n",
    "yi = find_nearest(ds[\"n\"], y)\n",
    "\n",
    "x = ds[\"m\"][xi]\n",
    "y = ds[\"n\"][yi]\n",
    "\n",
    "# Release a line of particles to find the best place for releasing the cluster.\n",
    "# x = ds[\"m\"][xi:xi+100].to_numpy()[()]\n",
    "# y = [ds[\"n\"][yi].to_numpy()[()]] * len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fda6b",
   "metadata": {},
   "source": [
    "Map with the Region of Interest (ROI) and the release point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1495259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import timedelta\n",
    "\n",
    "from parcels import JITParticle, ParticleSet, Variable\n",
    "\n",
    "npart = 10  # number of released particles\n",
    "lon = [x] * npart  # lon de liberacao das particulas\n",
    "lat = [y] * npart  # lat da liberacao das particulas\n",
    "repeatdt = timedelta(hours=24)\n",
    "\n",
    "lons, lats = [], []\n",
    "for k in range(npart):\n",
    "    lons.append(x + random.uniform(-1, 1) * 0.01)\n",
    "    lats.append(y + random.uniform(-1, 1) * 0.01)\n",
    "\n",
    "\n",
    "class AgeParticle(JITParticle):\n",
    "    age = Variable(\"age\", initial=0)\n",
    "\n",
    "\n",
    "pset = ParticleSet(\n",
    "    fieldset=fieldset,\n",
    "    pclass=AgeParticle,\n",
    "    lon=lons,\n",
    "    lat=lats,\n",
    "    repeatdt=repeatdt,\n",
    ")\n",
    "\n",
    "domain = {\n",
    "    \"N\": ds[\"latitude\"].max().to_numpy()[()],\n",
    "    \"S\": ds[\"latitude\"].min().to_numpy()[()],\n",
    "    \"E\": ds[\"longitude\"].max().to_numpy()[()],\n",
    "    \"W\": ds[\"longitude\"].min().to_numpy()[()],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45336131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from cartopy.mpl.gridliner import LATITUDE_FORMATTER, LONGITUDE_FORMATTER\n",
    "\n",
    "# Coastline\n",
    "feature = NaturalEarthFeature(\n",
    "    name=\"coastline\",\n",
    "    category=\"physical\",\n",
    "    scale=\"10m\",\n",
    "    edgecolor=\"#000000\",\n",
    "    facecolor=\"#AAAAAA\",\n",
    ")\n",
    "\n",
    "bbox = (\n",
    "    ds[\"longitude\"].min().to_numpy()[()],\n",
    "    ds[\"longitude\"].max().to_numpy()[()],\n",
    "    ds[\"latitude\"].min().to_numpy()[()],\n",
    "    ds[\"latitude\"].max().to_numpy()[()],\n",
    ")\n",
    "\n",
    "\n",
    "def creat_map(projection=ccrs.PlateCarree(), figsize=(9, 9)):\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=figsize,\n",
    "        subplot_kw={\n",
    "            \"projection\": projection,\n",
    "        },\n",
    "    )\n",
    "    gl = ax.gridlines(draw_labels=True)\n",
    "    gl.top_labels = gl.right_labels = False\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    ax.coastlines(resolution=\"10m\")\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# Figure\n",
    "fig, ax = creat_map(projection=ccrs.PlateCarree(), figsize=(9, 9))\n",
    "ax.plot(x, y, \"ro\", zorder=2)\n",
    "ax.plot(lons, lats, \"r.\", zorder=1, alpha=0.65)\n",
    "ax.add_feature(feature, zorder=0)\n",
    "ax.set_extent(bbox)\n",
    "\n",
    "ax.plot(\n",
    "    ds[\"longitude\"],\n",
    "    ds[\"latitude\"],\n",
    "    color=\"blue\",\n",
    "    marker=\"o\",\n",
    "    markerfacecolor=\"none\",\n",
    "    alpha=0.15,\n",
    "    zorder=0,\n",
    ")\n",
    "X, Y = np.meshgrid(ds[\"m\"], ds[\"n\"])\n",
    "ax.add_feature(feature, zorder=1)\n",
    "ax.plot(x, y, \"ro\")  # Itajaí\n",
    "ax.plot(X, Y, \"k.\", alpha=0.25, zorder=0, color=\"lightgrey\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d3431",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from parcels import AdvectionRK4, StatusCode\n",
    "\n",
    "\n",
    "def KeepInDomain(particle, fieldset, time):\n",
    "    # https://github.com/euroargodev/VirtualFleet/blob/4e524f24e15c5dfc6b8b4f57836953b2ccc9eafe/virtualargofleet/virtualargofleet.py\n",
    "    # out of geographical area : here we can delete the particle\n",
    "    if particle.state == StatusCode.ErrorOutOfBounds:\n",
    "        particle.delete()\n",
    "\n",
    "\n",
    "def Age(particle, fieldset, time):\n",
    "    # Create a custom kernel which keeps track of the particle age (minutes)\n",
    "    particle.age += particle.dt / 3600\n",
    "\n",
    "\n",
    "output_file = pset.ParticleFile(\n",
    "    name=\"results-model_tides_and_winds.zarr\", outputdt=timedelta(hours=12)\n",
    ")\n",
    "\n",
    "# kernels = pset.Kernel(AdvectionRK4) + pset.Kernel(KeepInDomain) + pset.Kernel(Age)\n",
    "kernels = [AdvectionRK4, KeepInDomain, Age]\n",
    "\n",
    "pset.execute(\n",
    "    kernels,\n",
    "    runtime=timedelta(days=29),\n",
    "    dt=timedelta(hours=6),\n",
    "    output_file=output_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa12214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def normalize_speed(u, v):\n",
    "    u_norm = u / np.sqrt(u**2.0 + v**2.0)\n",
    "    v_norm = v / np.sqrt(u**2.0 + v**2.0)\n",
    "    speed = (u**2 + v**2) ** 0.5\n",
    "    return (u_norm, v_norm, speed)\n",
    "\n",
    "\n",
    "fname = Path(\"avg-model_tides_and_winds.nc\")\n",
    "if not fname.exists():\n",
    "    avg = ds.mean(dim=\"time\")\n",
    "    avg.to_netcdf(fname)\n",
    "else:\n",
    "    avg = xr.load_dataset(fname)\n",
    "\n",
    "u = avg[\"velocity_x\"].squeeze()\n",
    "v = avg[\"velocity_y\"].squeeze()\n",
    "u_norm, v_norm, speed = normalize_speed(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = creat_map()\n",
    "ax.contourf(avg[\"longitude\"], avg[\"latitude\"], speed)\n",
    "ax.quiver(\n",
    "    avg[\"longitude\"],\n",
    "    avg[\"latitude\"],\n",
    "    u_norm,\n",
    "    v_norm,\n",
    "    color=\"white\",\n",
    "    scale=50,\n",
    ")\n",
    "\n",
    "ax.plot(x, y, \"bo\", label=\"Itajaí\")\n",
    "\n",
    "for p in pset:\n",
    "    ax.plot(p.lon, p.lat, \"r.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f626d",
   "metadata": {},
   "source": [
    "## Plot all trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e49144",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import trajan  # noqa\n",
    "import xarray as xr\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "ds = xr.open_zarr(\"results-model_tides_and_winds.zarr\")\n",
    "\n",
    "fig, ax = creat_map()\n",
    "ds.traj.plot(ax=ax)\n",
    "ax.add_feature(feature, zorder=99)\n",
    "ax.set_extent(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af431ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "\n",
    "\n",
    "def parcels_to_geopandas(ds, GB=5, suppress_warnings=False):\n",
    "    \"\"\"\n",
    "    Converts your parcels data to a geopandas dataframe containing a point for\n",
    "    every observation in the dataframe. Custom particle variables come along\n",
    "    for the ride during the transformation. Any undefined observations are removed\n",
    "    (correspond to the particle being deleted, or not having entered the simulation).\n",
    "\n",
    "    Assumes your parcel output is in lat and lon.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xr.Dataset\n",
    "        Dataset object in the format of parcels output.\n",
    "\n",
    "    suppress_warnings : bool\n",
    "        Whether to ignore RAM warning.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        GeoDataFrame with point data for each particle observation in the dataset.\n",
    "    \"\"\"\n",
    "    RAM_LIMIT_BYTES = GB * 1000 * 1000  #  GB RAM limit\n",
    "\n",
    "    if ds.nbytes > RAM_LIMIT_BYTES and not suppress_warnings:\n",
    "        raise MemoryError(\n",
    "            f\"Dataset is {ds.nbytes:_} bytes, but RAM_LIMIT_BYTES set max to be {RAM_LIMIT_BYTES:_}.\"\n",
    "        )\n",
    "\n",
    "    df = (\n",
    "        ds.to_dataframe().reset_index()  # Convert `obs` and `trajectory` indices to be columns instead\n",
    "    )\n",
    "\n",
    "    gdf = (\n",
    "        geopandas.GeoDataFrame(\n",
    "            df, geometry=geopandas.points_from_xy(df[\"lon\"], df[\"lat\"])\n",
    "        )\n",
    "        .drop(\n",
    "            [\"lon\", \"lat\"], axis=1\n",
    "        )  # No need for lon and lat cols. Included in geometry attribute\n",
    "        .set_crs(\n",
    "            \"EPSG:4326\"\n",
    "        )  # Set coordinate reference system to EPSG:4326 (aka. WGS84; the lat lon reference system)\n",
    "    )\n",
    "\n",
    "    # Remove observations with no time from gdf (indicate particle has been removed, or isn't in simulation)\n",
    "    invalid_observations = gdf[\"time\"].isna()\n",
    "    return gdf[~invalid_observations]\n",
    "\n",
    "\n",
    "gdf_parcels = parcels_to_geopandas(ds)\n",
    "gdf_parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7373d6be",
   "metadata": {},
   "source": [
    "# Filter trajectories after first beaching\n",
    "\n",
    "There are two land masks, one with Bonbinhas and another with without. Both where created with the `polygon_roi.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cef2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = geopandas.read_file(\"data/roi-no-bombinhas.geojon\")[\"geometry\"].squeeze()\n",
    "\n",
    "filtered_traj = {}\n",
    "beached = {}\n",
    "for k, traj in gdf_parcels.groupby(\"trajectory\"):\n",
    "    mask = traj.within(roi)\n",
    "    if any(mask):\n",
    "        # The beached particle is the first one that hit land.\n",
    "        b = traj[mask].iloc[0]\n",
    "        beached.update({k: b})\n",
    "        filtered_traj.update({k: traj.iloc[: b[\"obs\"]]})\n",
    "    else:\n",
    "        filtered_traj.update({k: traj})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7767a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(beached)} particules beached out of {len(filtered_traj)} total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d389a1b0",
   "metadata": {},
   "source": [
    "## Plot only filtered trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c71a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = creat_map()\n",
    "\n",
    "# non_beached = set(beached.keys()).symmetric_difference(ds[\"trajectory\"].to_numpy())\n",
    "# non_beached = ds.sel(trajectory=list(non_beached))\n",
    "# filtered_traj.traj.plot(ax=ax)\n",
    "\n",
    "for traj in filtered_traj.values():\n",
    "    ax.plot(traj[\"geometry\"].x, traj[\"geometry\"].y, color=\"gray\", alpha=0.55)\n",
    "ax.add_feature(feature, zorder=99)\n",
    "ax.set_extent(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import Fullscreen\n",
    "\n",
    "m = folium.Map()\n",
    "for k, point in beached.items():\n",
    "    folium.GeoJson(point[\"geometry\"]).add_to(m)\n",
    "    trajectory = gdf_parcels.loc[gdf_parcels[\"trajectory\"] == point[\"trajectory\"]]\n",
    "folium.GeoJson(roi).add_to(m)\n",
    "m.fit_bounds(m.get_bounds())\n",
    "Fullscreen().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee0f0a",
   "metadata": {},
   "source": [
    "## All particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f0129",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import contextily\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "gdf_parcels.plot(ax=ax, markersize=0.1, color=\"k\", zorder=2)\n",
    "g = sns.kdeplot(\n",
    "    data=gdf_parcels,\n",
    "    x=gdf_parcels[\"geometry\"].x,\n",
    "    y=gdf_parcels[\"geometry\"].y,\n",
    "    fill=True,\n",
    "    cmap=\"crest\",\n",
    "    alpha=0.6,\n",
    "    levels=7,\n",
    ")\n",
    "\n",
    "contextily.add_basemap(\n",
    "    ax=ax,\n",
    "    crs=gdf_parcels.crs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e0136e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_beached = ds.sel(trajectory=list(beached.keys()))\n",
    "\n",
    "gdf_beached = parcels_to_geopandas(ds_beached)\n",
    "gdf_beached\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "gdf_parcels.plot(ax=ax, markersize=0.1, color=\"k\", zorder=2)\n",
    "g = sns.kdeplot(\n",
    "    data=gdf_beached,\n",
    "    x=gdf_beached[\"geometry\"].x,\n",
    "    y=gdf_beached[\"geometry\"].y,\n",
    "    fill=True,\n",
    "    cmap=\"crest\",\n",
    "    alpha=0.6,\n",
    "    levels=7,\n",
    ")\n",
    "\n",
    "contextily.add_basemap(ax=ax, crs=gdf_beached.crs, source=\"OpenStreetMap.Mapnik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c77a9",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Implement the `CoastalProximityParticle` class is taken from [3] and creates a \"beaching\" effect for particles that have beem close to the shore for a number of days in the vicinity of the virtual shore line.\n",
    "\n",
    "[3] https://github.com/VictorOnink/Modeling-Global-Plastic-Beaching/blob/main/generalBeachingScenarios.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
